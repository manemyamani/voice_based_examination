# Aura Assist - Voice-Based Examination System

Aura Assist is an AI-powered voice-based examination system designed to assist blind individuals in taking assessments independently. It leverages advanced speech-to-text and text-to-speech technologies to facilitate a seamless examination process.

## Features

- **Voice-Based Interface**: Converts text-based questions into speech and records spoken answers.
- **Face Verification**: Ensures candidate authentication using OpenCV and dlib.
- **Speech-to-Text & Text-to-Speech**: Uses Wave2Vec 2.0 for speech recognition and Tacotron for speech synthesis.
- **Secure & User-Friendly**: Designed to provide a secure, accessible, and intuitive examination experience.

## Tech Stack

- **Frontend**: React
- **Backend**: Python (Flask)
- **Speech Processing**: Wave2Vec 2.0, Tacotron
- **Face Recognition**: OpenCV, dlib
- **Database**: SQLite/MySQL

## Usage

- The system will prompt users with questions through audio.
- Candidates can respond verbally, and the system will transcribe their answers.
- Facial verification ensures secure access before the examination starts.
- Results and analytics can be stored and accessed for further evaluation.

## Contributing

Contributions are welcome! Feel free to fork the repository and submit a pull request.

## Contact

For any inquiries or support, contact:

- **Your Name**
- Email: [your.email@example.com](yaminimanem28@gmail.com)
- GitHub: [Your GitHub Profile](https://github.com/manemyamani)

---